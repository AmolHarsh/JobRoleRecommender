{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28076a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all the  necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException  # This line is important\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "opts = Options ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a157cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to ensure all key data fields have a value\n",
    "\n",
    "def validate_field(field):\n",
    "    #if field is present pass if field:\n",
    "    if field:\n",
    "        pass\n",
    "    #if field is not present print text else:\n",
    "    else:\n",
    "        field = 'No results'\n",
    "    return field\n",
    "\n",
    "#driver get method() will navigate to a page given by the URL address.\n",
    "driver.get(\"https://www.linkedin.com/\")\n",
    "\n",
    "#locate email form by_class_name\n",
    "username = driver.find_element(By.ID, 'session_key')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "username.send_keys('2023mlpr@gmail.com')\n",
    "\n",
    "#sleep for 0.5 seconds\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate password form by_class_name\n",
    "password = driver.find_element(By.ID, 'session_password')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "password.send_keys('MLPR2023')\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate submit button by_xpath\n",
    "sign_in_button = driver.find_element(By.XPATH,'//*[@type=\"submit\"]')\n",
    "\n",
    "#.click() to mimic button click\n",
    "sign_in_button.click()\n",
    "\n",
    "sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96421ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/priya-sidhu-62a516180\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/priya-sharma-24303b240\n",
      "checkpoint3\n",
      "checkpoint4\n"
     ]
    }
   ],
   "source": [
    "#sleep(15)\n",
    "\n",
    "sleep(5)\n",
    "Jobdata = []\n",
    "lnks = []\n",
    "for x in range(0,20,10):\n",
    "    driver.get(f'https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Python+Developer%22+AND+%22Delhi%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start={x}')\n",
    "    time.sleep(random.uniform(2.5,4.9))\n",
    "    print(\"checkpoint1\")\n",
    "    try:\n",
    "        linkedin_url = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[@jsname='UWckNb']\"))).get_attribute(\"href\")\n",
    "        print(\"working:\", linkedin_url)\n",
    "        linkedin_urls = [my_elem.get_attribute(\"href\") for my_elem in WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@jsname='UWckNb']\")))]\n",
    "        print(\"checkpoint3\")\n",
    "        lnks.append(linkedin_urls)\n",
    "        print(\"checkpoint4\")\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException: Elements not found within the specified time.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50c3c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i https://www.linkedin.com/in/sahil-mittal-594925146/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'educationInfo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m about \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH,\u001b[39m'\u001b[39m\u001b[39m//div[contains(@class, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpv-shared-text-with-see-more full-width t-14 t-normal t-black display-flex align-items-center\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#Extracting the education\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m education \u001b[39m=\u001b[39m educationInfo(i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#Extracting the experience\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryamankhandelwal/Documents/Plaksha/Sem5/MLPR/Project/JobRoleRecommender/web_scraper.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m experience \u001b[39m=\u001b[39m experienceSection(i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'educationInfo' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# THIS IS THE CODE USED FOR ONLY ONE JOB PROFILE\n",
    "\n",
    "i = \"https://www.linkedin.com/in/sahil-mittal-594925146/\"\n",
    "print(\"i\", i)\n",
    "# Get the profile URL\n",
    "driver.get(i)\n",
    "time.sleep(random.uniform(2.5, 4.9))\n",
    "newProfile = {}\n",
    "\n",
    "# Assigning the source code for the web page to a variable\n",
    "page_source = driver.page_source\n",
    "sel = Selector(text=page_source)\n",
    "\n",
    "# Extract name\n",
    "name_element = driver.find_element(By.XPATH, '//h1[contains(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]')\n",
    "name = name_element.text.strip() if name_element else None\n",
    "\n",
    "# Extract job title\n",
    "job_title_element = driver.find_element(By.XPATH, '//div[contains(@class, \"text-body-medium break-words\")]')\n",
    "job_title = job_title_element.text.strip() if job_title_element else None\n",
    "\n",
    "#Extract about section\n",
    "about = driver.find_element(By.XPATH,'//div[contains(@class, \"pv-shared-text-with-see-more full-width t-14 t-normal t-black display-flex align-items-center\")]').text\n",
    "\n",
    "#Extracting the education\n",
    "education = educationInfo(i)\n",
    "\n",
    "#Extracting the experience\n",
    "experience = experienceSection(i)\n",
    "\n",
    "\n",
    "\n",
    "newProfile[\"name\"] = [name]\n",
    "newProfile[\"currentJobTitle\"] = [job_title]\n",
    "newProfile[\"about\"] = [about]\n",
    "newProfile[\"education_from_date\"] = education[0]\n",
    "newProfile[\"education_to_date\"] = [education[1]]\n",
    "newProfile[\"education_description\"] = education[2]\n",
    "newProfile[\"education_degree\"] = education[3]\n",
    "newProfile[\"education_institution_name\"] = education[4]\n",
    "newProfile[\"experience_section_position_title\"] = experience[0]\n",
    "newProfile[\"experience_section_from_date\"] = experience[1]\n",
    "newProfile[\"experience_section_to_date\"] = experience[2]\n",
    "newProfile[\"experience_section_description\"] = experience[3]\n",
    "newProfile[\"experience_section_duration\"] = experience[4]\n",
    "newProfile[\"experience_section_company\"] = experience[5]\n",
    "newProfile[\"experience_section_location\"] = experience[6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211f1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['Sahil Mittal'],\n",
       " 'currentJobTitle': ['Reimagining Tech Education @Plaksha University | Young India Fellow | NIT Trichy'],\n",
       " 'about': [\"As a Senior Associate at Plaksha University, I help create and nurture corporate partnerships and careers for India's premier technology university. I work with a dynamic team to connect students with industry opportunities, while also supporting them in building their profiles and preparing for interviews. I am proud to be part of a mission to transform the future of technology education and research in India, and to contribute to the growth and success of the companies and the students.\\n\\nI am also an editor-in-chief at Zeroing In, a platform that aims to make complex topics accessible and engaging for everyone. I lead a team of writers and editors who produce high-quality content on topics such as space, science, philosophy, and history. I have a passion for learning and sharing my knowledge, and I enjoy giving talks and workshops on these topics. I hold a Young India Fellowship from Ashoka University, and a Bachelor of Technology from NIT Trichy, with a minor in Physics. My core competencies include writing, communication, and education.\"],\n",
       " 'education_from_date': ['Aug 2021', 'Jul 2017', 'Apr 2001'],\n",
       " 'education_to_date': ['Jun 2022', 'May 2021', 'May 2017'],\n",
       " 'education_description': ['Grade: 3.23/4.0\\nGrade: 3.23/4.0\\nActivities and societies: Critical Writing Course under the theme \"History and Politics of Representation of Madness in Literature and Art.\"\\nActivities and societies: Critical Writing Course under the theme \"History and Politics of Representation of Madness in Literature and Art.\"\\nThe Young India Fellowship is a flagship, year-long, residential postgraduate diploma program in Liberal Studies offered by Ashoka University. The program aims to groom socially conscious leaders and change-makers for the 21st century. As a YIF Fellow, I had the opportunity to engage in a multidisciplinary and multidimensional education that exposed me to diverse areas of study, research, and practice.\\n\\nDuring the immersive and rigorous year on campus, I studied a curated selection of courses taught by renowned educators, worked on team-based projects to solve real-world problems, and learned how to think critically and write effectively. I was also mentored by inspiring individuals and lived with a community of diverse individuals from many walks of life.\\nThe Young India Fellowship is a flagship, year-long, residential postgraduate diploma program in Liberal Studies offered by Ashoka University. The program aims to groom socially conscious leaders and change-makers for the 21st century. As a YIF Fellow, I had the opportunity to engage in a multidisciplinary and multidimensional education that exposed me to diverse areas of study, research, and practice. During the immersive and rigorous year on campus, I studied a curated selection of courses taught by renowned educators, worked on team-based projects to solve real-world problems, and learned how to think critically and write effectively. I was also mentored by inspiring individuals and lived with a community of diverse individuals from many walks of life.\\nSkills: Management · Storytelling · Critical Thinking · Writing · Public Speaking\\nManagement · Storytelling · Critical Thinking · Writing · Public Speaking',\n",
       "  'Grade: 7.5/10\\nGrade: 7.5/10\\nActivities and societies: Led several teams during 4-year degree including Astronomy Club, Orientation team, and Content team for the MUN club. Served as president and spokesperson for Nakshatra - The Astronomy and Science Club.\\nActivities and societies: Led several teams during 4-year degree including Astronomy Club, Orientation team, and Content team for the MUN club. Served as president and spokesperson for Nakshatra - The Astronomy and Science Club.\\nAs a student of the B.Tech. degree course in EEE from NIT Trichy, I gained a strong foundation in Electrical and Electronics Engineering subjects such as Machines and Power Systems, as well as a background in Applied Electronics and Computer Applications. The curriculum was designed to produce engineers with sound knowledge in all subjects of Electrical Engineering, who can also orient themselves in any of the above areas and take up challenging jobs in the industries and engage themselves in research and development activities. \\n\\nI pursued a minor in Physics alongside my core curriculum, which provided me with a deeper understanding of the fundamental principles underlying the field. The minor courses covered topics such as Classical Mechanics, Electromagnetic Theory, Quantum Mechanics, and Statistical Mechanics. Earning this degree has equipped me with a strong foundation in the field and prepared me for a successful career as an engineer.\\nAs a student of the B.Tech. degree course in EEE from NIT Trichy, I gained a strong foundation in Electrical and Electronics Engineering subjects such as Machines and Power Systems, as well as a background in Applied Electronics and Computer Applications. The curriculum was designed to produce engineers with sound knowledge in all subjects of Electrical Engineering, who can also orient themselves in any of the above areas and take up challenging jobs in the industries and engage themselves in research and development activities. I pursued a minor in Physics alongside my core curriculum, which provided me with a deeper understanding of the fundamental principles underlying the field. The minor courses covered topics such as Classical Mechanics, Electromagnetic Theory, Quantum Mechanics, and Statistical Mechanics. Earning this degree has equipped me with a strong foundation in the field and prepared me for a successful career as an engineer.\\nSkills: Team Management · Electrical Engineering · Electronics · Python (Programming Language) · Astronomy\\nTeam Management · Electrical Engineering · Electronics · Python (Programming Language) · Astronomy',\n",
       "  'Grade: 93.8/100 (PCM)\\nGrade: 93.8/100 (PCM)\\nActivities and societies: Represented the School in various quiz, science, and debate competitions. \\nWon awards for academic performance.\\nDistrict Level Badminton Player.\\nActivities and societies: Represented the School in various quiz, science, and debate competitions. Won awards for academic performance. District Level Badminton Player.\\nSkills: Education · Chemistry · Science · Physics · Mathematics\\nEducation · Chemistry · Science · Physics · Mathematics'],\n",
       " 'education_degree': ['Young India Fellowship , Liberal Arts and Sciences/Liberal Studies',\n",
       "  'Bachelor of Technology, Electrical and Electronics Engineering, Minor in Physics',\n",
       "  'High School Diploma, Science'],\n",
       " 'education_institution_name': ['Ashoka University',\n",
       "  'National Institute of Technology, Tiruchirappalli',\n",
       "  'DAV Public School Patiala'],\n",
       " 'experience_section_position_title': ['Senior Associate, Corporate Partnersips and Careers',\n",
       "  'Core Team\\nCore Team',\n",
       "  'Editor in Chief\\nEditor in Chief',\n",
       "  'Teaching Fellow\\nTeaching Fellow',\n",
       "  'Teaching Fellow\\nTeaching Fellow',\n",
       "  'Research Associate',\n",
       "  'Senior Teacher',\n",
       "  'President\\nPresident',\n",
       "  'VicePresident\\nVicePresident',\n",
       "  'Content Writer',\n",
       "  'Head Of Content',\n",
       "  'Summer Research Fellow'],\n",
       " 'experience_section_from_date': ['May 2023',\n",
       "  'Jan 2023',\n",
       "  'Jan 2022',\n",
       "  'Part-time',\n",
       "  'Full-time',\n",
       "  'Feb 2023',\n",
       "  'Jul 2022',\n",
       "  'Mar 2020',\n",
       "  'Apr 2019',\n",
       "  'Aug 2018',\n",
       "  'Jan 2019',\n",
       "  'May 2019'],\n",
       " 'experience_section_to_date': [\"As a key member of the Plaksha University team, this role involves helping the creation of the Office of Corporate Partnerships and Careers (CPC) at India's premier technology university. The primary responsibility is to establish and nurture relationships with corporate partners, while also helping students build their profiles and prepare for industry and interviews. \\n\\nThrough this role, the impact extends beyond the walls of the university, contributing to the growth of the companies and the success of the students. The team plays an instrumental role in transforming the future of technology education and research in India, creating mutually beneficial long-term relationships between students and organizations. \\n\\nPlaksha University is India's largest collective philanthropy effort to reimagine and build a new model of technology education and research.\\nAs a key member of the Plaksha University team, this role involves helping the creation of the Office of Corporate Partnerships and Careers (CPC) at India's premier technology university. The primary responsibility is to establish and nurture relationships with corporate partners, while also helping students build their profiles and prepare for industry and interviews. Through this role, the impact extends beyond the walls of the university, contributing to the growth of the companies and the success of the students. The team plays an instrumental role in transforming the future of technology education and research in India, creating mutually beneficial long-term relationships between students and organizations. Plaksha University is India's largest collective philanthropy effort to reimagine and build a new model of technology education and research.\",\n",
       "  'nan',\n",
       "  'Skills: Science · Editing · Blogging · Communication · Writing\\nScience · Editing · Blogging · Communication · Writing',\n",
       "  'May 2023 - Jul 2023 · 3 mos',\n",
       "  'Dec 2022 - May 2023 · 6 mos\\nSkills: Design Thinking · Entrepreneurship Education · Assistant Teaching · Project Management · Python (Programming Language)\\nDesign Thinking · Entrepreneurship Education · Assistant Teaching · Project Management · Python (Programming Language)',\n",
       "  'Skills: Microsoft Excel · Database Administration · Team Management · Leadership · Microsoft Office · Microsoft Word\\nMicrosoft Excel · Database Administration · Team Management · Leadership · Microsoft Office · Microsoft Word',\n",
       "  'Skills: Teaching · Team Management · English Teaching · Teaching maths\\nTeaching · Team Management · English Teaching · Teaching maths',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'nan'],\n",
       " 'experience_section_description': ['Present',\n",
       "  'Present',\n",
       "  'Present',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'May 2023',\n",
       "  'Sep 2022',\n",
       "  'May 2021',\n",
       "  'Mar 2020',\n",
       "  'May 2021',\n",
       "  'Jul 2020',\n",
       "  'Jul 2019'],\n",
       " 'experience_section_duration': ['5 mos',\n",
       "  '9 mos',\n",
       "  '1 yr 9 mos',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  '4 mos',\n",
       "  '3 mos',\n",
       "  '1 yr 3 mos',\n",
       "  '1 yr',\n",
       "  '2 yrs 10 mos',\n",
       "  '1 yr 7 mos',\n",
       "  '3 mos'],\n",
       " 'experience_section_company': ['Office of Corporate Partnerships and Careers at Plaksha University · Full-time',\n",
       "  'Zeroing In',\n",
       "  'Zeroing In',\n",
       "  '8 mos',\n",
       "  '8 mos',\n",
       "  'Plaksha University · Part-time',\n",
       "  'The Levelfield School · Full-time',\n",
       "  'The Levelfield School · Full-time',\n",
       "  'The Levelfield School · Full-time',\n",
       "  \"Pragyan - NIT Trichy's Techno-managerial Organisation\",\n",
       "  'Athenæum - The NITT MUN Society',\n",
       "  'Indian Academy of Sciences · Internship'],\n",
       " 'experience_section_location': ['Mohali district, Punjab, India · On-site',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'May 2023 - Jul 2023 · 3 mos',\n",
       "  'Dec 2022 - May 2023 · 6 mos',\n",
       "  'Hybrid',\n",
       "  'Suri, West Bengal, India',\n",
       "  'nan',\n",
       "  'nan',\n",
       "  'Tiruchchirappalli Area, India',\n",
       "  'National Institute of Technology, Trichy',\n",
       "  'nan']}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newProfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for x in equal_length_profile:\n",
    "    print(len(equal_length_profile[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the maximum length among all lists\n",
    "max_len = max(len(newProfile[key]) for key in newProfile)\n",
    "\n",
    "# Fill in missing values with None to make the lists of equal length\n",
    "equal_length_profile = {key: (value + [None] * (max_len - len(value))) for key, value in newProfile.items()}\n",
    "\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(equal_length_profile) \n",
    "\n",
    "# Define the Excel file path where you want to save the DataFrame\n",
    "excel_file_path = \"sample_data.xlsx\"\n",
    "\n",
    "# Write the DataFrame to the Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "\n",
    "# # Append the DataFrame to an existing Excel file or create a new one if it doesn't exist\n",
    "# with pd.ExcelWriter(\"linkedin_profiles.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "#     df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "# for x in newProfile:\n",
    "#     print((newProfile[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515e2a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lnks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q8/6ygp14f90fs0hmwczw4f64v80000gn/T/ipykernel_68799/3014106197.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprofile_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlnks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnewProfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lnks' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is the code, that extracts profile details for the whole group\n",
    "\n",
    "# This function used for waiting\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "profile_data = []\n",
    "for x in lnks:\n",
    "    newProfile = {}\n",
    "    for i in x:\n",
    "        # Get the profile URL\n",
    "        driver.get(i)\n",
    "        time.sleep(random.uniform(2.5, 4.9))\n",
    "\n",
    "        # Assigning the source code for the web page to a variable\n",
    "        page_source = driver.page_source\n",
    "        sel = Selector(text=page_source)\n",
    "        \n",
    "        # Extract name\n",
    "        name_element = driver.find_element(By.XPATH, '//h1[contains(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]')\n",
    "        name = name_element.text.strip() if name_element else \"nan\"\n",
    "\n",
    "        # Extract job title\n",
    "        job_title_element = driver.find_element(By.XPATH, '//div[contains(@class, \"text-body-medium break-words\")]')\n",
    "        job_title = job_title_element.text.strip() if job_title_element else \"nan\"\n",
    "\n",
    "        #Extract about section\n",
    "        about = driver.find_element(By.XPATH,'//div[contains(@class, \"inline-show-more-text         inline-show-more-text--is-collapsed         inline-show-more-text--is-collapsed-with-line-clamp                            full-width\")]').text\n",
    "        about = about.text.strip() if about else \"nan\"\n",
    "        \n",
    "        #the function returns\n",
    "        #[education_from_date, education_to_date, education_description, education_degree, education_institution_name]\n",
    "\n",
    "    \n",
    "        #Extracting the education\n",
    "        education = educationInfo(i)\n",
    "        \n",
    "        #The below function returns:\n",
    "        #[experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "        \n",
    "        #Extracting the experience\n",
    "        experience = experienceSection(i)\n",
    "        \n",
    "        print(name)\n",
    "        print(job_title)\n",
    "        print(about)\n",
    "        print(education)\n",
    "        print(experience)\n",
    "        \n",
    "        newProfile[\"name\"] = name_element\n",
    "        newProfile[\"currentJobTitle\"] = job_title\n",
    "        newProfile[\"about\"] = about\n",
    "        newProfile[\"education_from_date\"] = education[0]\n",
    "        newProfile[\"education_to_date\"] = education[1]\n",
    "        newProfile[\"education_description\"] = education[2]\n",
    "        newProfile[\"education_degree\"] = education[3]\n",
    "        newProfile[\"education_institution_name\"] = education[4]\n",
    "        \n",
    "        newProfile[\"experience_section_position_title\"] = experience[0]\n",
    "        newProfile[\"experience_section_from_date\"] = experience[1]\n",
    "        newProfile[\"experience_section_to_date\"] = experience[2]\n",
    "        newProfile[\"experience_section_description\"] = experience[3]\n",
    "        newProfile[\"experience_section_duration\"] = experience[4]\n",
    "        newProfile[\"experience_section_company\"] = experience[5]\n",
    "        newProfile[\"experience_section_location\"] = experience[6]\n",
    "        \n",
    "              \n",
    "        \n",
    "        df = pd.DataFrame(profile_data)\n",
    "\n",
    "        # Append the DataFrame to an existing Excel file or create a new one if it doesn't exist\n",
    "        with pd.ExcelWriter(\"linkedin_profiles.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "# Terminate the application\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a314a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aug 2021', 'Jul 2017', 'Apr 2001']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newProfile[\"education_from_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5292a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is solely for educational feature\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "url = \"https://www.linkedin.com/in/apratim-chandra-singh-39a67a64/\"\n",
    "\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "#the function returns\n",
    "#[education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "def educationInfo(url):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        url = os.path.join(url,\"details/education\")\n",
    "        driver.get(url)\n",
    "        main = wait_for_element_to_load(by = By.TAG_NAME, name = \"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        education_from_date = \"\"\n",
    "        education_to_date = \"\"\n",
    "        education_description = \"\"\n",
    "        education_degree = \"\"\n",
    "        education_institution_name = \"\"\n",
    "\n",
    "\n",
    "        for position in main_list.find_elements(By.CLASS_NAME,\"pvs-entity\"):\n",
    "                institution_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "                # company elem\n",
    "                institution_linkedin_url = institution_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "                # position details\n",
    "                position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "                position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "                position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "                outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "                institution_name = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                degree = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "                if len(outer_positions) > 2:\n",
    "                    times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    dates = times.split('-')\n",
    "                    from_date = dates[0].strip()\n",
    "                    to_date = dates[1].strip()\n",
    "                else:\n",
    "                    from_date = None\n",
    "                    to_date = None\n",
    "\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "                print()\n",
    "                education_from_date = education_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                education_to_date = education_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                education_description = education_description + \"-:-\" + emptyChecker(description)\n",
    "                education_degree = education_degree + \"-:-\" + emptyChecker(degree)\n",
    "                education_institution_name = education_institution_name + \"-:-\" + emptyChecker(institution_name)\n",
    "                \n",
    "#                 education_from_date.append(emptyChecker(from_date))\n",
    "#                 education_to_date.append(emptyChecker(to_date))\n",
    "#                 education_description.append(emptyChecker(description))\n",
    "#                 education_degree.append(emptyChecker(degree))\n",
    "#                 education_institution_name.append(emptyChecker(institution_name))\n",
    "\n",
    "#                 print(\"From Date:\", from_date)\n",
    "#                 print(\"To Date:\", to_date)\n",
    "#                 print(\"Description:\", description)\n",
    "#                 print(\"Degree:\", degree)\n",
    "#                 print(\"Institution Name:\", institution_name)\n",
    "#                 print(\"********************\")\n",
    "\n",
    "        return [education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        return [\"nan\", \"nan\", \"nan\", \"nan\", \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ed64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is solely for experience section\n",
    "\n",
    "\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "def removingExtraLine(descrip):\n",
    "    \n",
    "    # Define a regular expression pattern to match a date range format\n",
    "    date_pattern = r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} · \\d+ mos\\b\"\n",
    "\n",
    "    # Use re.search() to find the date range pattern in the first line\n",
    "    match = re.search(date_pattern, descrip)\n",
    "\n",
    "    # If a match is found in the first line, remove that line\n",
    "    if match and match.start() == 0:\n",
    "        lines = descrip.split('\\n', 1)  # Split the data into lines, starting from the first newline\n",
    "        if len(lines) > 1:\n",
    "            descrip = lines[1]  # Keep the data after the first line\n",
    "            \n",
    "    return descrip\n",
    "\n",
    "\n",
    "# Function to extract description\n",
    "def extract_description(data):\n",
    "    # Split the data by lines\n",
    "    lines = data.strip().split('\\n')\n",
    "    \n",
    "    # Extract the description part (after date)\n",
    "    description = '\\n'.join(lines[4:])\n",
    "    description = removingExtraLine(description)\n",
    "    return description\n",
    "\n",
    "\n",
    "url = \"https://www.linkedin.com/in/apratim-chandra-singh-39a67a64/\"\n",
    "\n",
    "#The below function returns:\n",
    "#[experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "#\n",
    "def experienceSection(url):\n",
    "\n",
    "    try:    \n",
    "        url = os.path.join(url, \"details/experience\")\n",
    "        driver.get(url)\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "\n",
    "        experience_section_position_title = \"\"\n",
    "        experience_section_from_date = \"\"\n",
    "        experience_section_to_date = \"\"\n",
    "        experience_section_duration = \"\"\n",
    "        experience_section_description = \"\"\n",
    "        experience_section_company = \"\"\n",
    "        experience_section_location = \"\"\n",
    "\n",
    "        for position in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            position = position.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            company_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "\n",
    "            # company elem\n",
    "            company_linkedin_url = company_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "            # position details\n",
    "            position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "            position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "            position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "            outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "\n",
    "            if len(outer_positions) == 4:\n",
    "                position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                location = outer_positions[3].find_element(By.TAG_NAME,\"span\").text\n",
    "            elif len(outer_positions) == 3:\n",
    "                if \"·\" in outer_positions[2].text:\n",
    "                    position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = \"\"\n",
    "                else:\n",
    "                    position_title = \"\"\n",
    "                    company = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "            times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "            duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "\n",
    "            from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "            to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "            if position_summary_text and len(position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")) > 1:\n",
    "                descriptions = position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")\n",
    "                for description in descriptions:\n",
    "                    res = description.find_element(By.TAG_NAME,\"a\").find_elements(By.XPATH,\"*\")\n",
    "                    position_title_elem = res[0] if len(res) > 0 else None\n",
    "                    work_times_elem = res[1] if len(res) > 1 else None\n",
    "                    location_elem = res[2] if len(res) > 2 else None\n",
    "\n",
    "\n",
    "                    location = location_elem.find_element(By.XPATH,\"*\").text if location_elem else None\n",
    "                    position_title = position_title_elem.find_element(By.XPATH,\"*\").find_element(By.TAG_NAME,\"*\").text if position_title_elem else \"\"\n",
    "                    work_times = work_times_elem.find_element(By.XPATH,\"*\").text if work_times_elem else \"\"\n",
    "                    times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "                    duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "                    from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "                    to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "\n",
    "\n",
    "                    # print(position_title,from_date,to_date,duration,location,description,company,company_linkedin_url)\n",
    "\n",
    "#                     print(\"Position Title:\",position_title)\n",
    "#                     print(\"From date\",from_date)\n",
    "#                     print(\"End date:\",to_date)\n",
    "#                     print(\"Duration:\",duration)\n",
    "#                     print(\"Location\",location)\n",
    "#                     print(\"~~~~~~~~~~~~~~~~~~~~~~#$$$$$$$~~~~~~~~~~~~~~~~`\")\n",
    "\n",
    "                    if description:\n",
    "                        text = description.text\n",
    "                        description = extract_description(text)\n",
    "\n",
    "#                     print(\"~~~~~~~~~~~~~~~~~~~~~~#$$$$$$$~~~~~~~~~~~~~~~~`\")\n",
    "#                     print(\"Description:\",description)\n",
    "#                     print(\"Company:\",company)\n",
    "#                     print()\n",
    "#                     print()\n",
    "                    experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                    experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                    experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                    experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                    experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                    experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                    experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "#         experience_section_position_title.append(emptyChecker(position_title))\n",
    "#                     experience_section_from_date.append(emptyChecker(from_date))\n",
    "#                     experience_section_to_date.append(emptyChecker(to_date))\n",
    "#                     experience_section_duration.append(emptyChecker(duration))\n",
    "#                     experience_section_description.append(emptyChecker(description))\n",
    "#                     experience_section_company.append(emptyChecker(company))\n",
    "#                     experience_section_location.append(emptyChecker(location))\n",
    "            else:\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "\n",
    "                # print(position_title,from_date,to_date,duration,location,description,company,company_linkedin_url)\n",
    "#                 print(\"Position Title:\",position_title)\n",
    "#                 print(\"From date\",from_date)\n",
    "#                 print(\"End date:\",to_date)\n",
    "#                 print(\"Duration:\",duration)\n",
    "#                 print(\"Location\",location)\n",
    "#                 print(\"Description:\",description)\n",
    "#                 print(\"Company:\",company)\n",
    "#                 print()\n",
    "#                 print()\n",
    "\n",
    "                experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "\n",
    "#                 experience_section_position_title.append(emptyChecker(position_title))\n",
    "#                 experience_section_from_date.append(emptyChecker(from_date))\n",
    "#                 experience_section_to_date.append(emptyChecker(to_date))\n",
    "#                 experience_section_duration.append(emptyChecker(duration))\n",
    "#                 experience_section_description.append(emptyChecker(description))\n",
    "#                 experience_section_company.append(emptyChecker(company))\n",
    "#                 experience_section_location.append(emptyChecker(location))\n",
    "\n",
    "\n",
    "\n",
    "        return [experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "    except:\n",
    "        return [\"nan\",\"nan\", \"nan\", \"nan\", \"nan\",  \"nan\", \"nan\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c77b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09450905",
   "metadata": {},
   "source": [
    "# Extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00613fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 1 Description:\n",
      "Building JobHai ✅\n",
      "\n",
      "Blue collar recruitment product for the Next Half Billion\n",
      "Building JobHai ✅ Blue collar recruitment product for the Next Half Billion\n",
      "\n",
      "Data 2 Description:\n",
      "Transitioned to Senior Business Analyst in Business Intelligence Functional Unit of Job Hai to build data products for analysis and visualisation.\n",
      "Transitioned to Senior Business Analyst in Business Intelligence Functional Unit of Job Hai to build data products for analysis and visualisation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data1 = \"\"\"\n",
    "Product Manager\n",
    "Product Manager\n",
    "Aug 2022 - Apr 2023 · 9 mos\n",
    "Aug 2022 - Apr 2023 · 9 mos\n",
    "Building JobHai ✅\n",
    "\n",
    "Blue collar recruitment product for the Next Half Billion\n",
    "Building JobHai ✅ Blue collar recruitment product for the Next Half Billion\n",
    "\"\"\"\n",
    "\n",
    "data2 = \"\"\"\n",
    "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
    "Senior Business Analyst\n",
    "Senior Business Analyst\n",
    "Apr 2023 - Jun 2023 · 3 mos\n",
    "Apr 2023 - Jun 2023 · 3 mos\n",
    "Transitioned to Senior Business Analyst in Business Intelligence Functional Unit of Job Hai to build data products for analysis and visualisation.\n",
    "Transitioned to Senior Business Analyst in Business Intelligence Functional Unit of Job Hai to build data products for analysis and visualisation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def removingExtraLine(descrip):\n",
    "    \n",
    "    # Define a regular expression pattern to match a date range format\n",
    "    date_pattern = r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} · \\d+ mos\\b\"\n",
    "\n",
    "    # Use re.search() to find the date range pattern in the first line\n",
    "    match = re.search(date_pattern, descrip)\n",
    "\n",
    "    # If a match is found in the first line, remove that line\n",
    "    if match and match.start() == 0:\n",
    "        lines = descrip.split('\\n', 1)  # Split the data into lines, starting from the first newline\n",
    "        if len(lines) > 1:\n",
    "            descrip = lines[1]  # Keep the data after the first line\n",
    "            \n",
    "    return descrip\n",
    "\n",
    "\n",
    "# Function to extract description\n",
    "def extract_description(data):\n",
    "    # Split the data by lines\n",
    "    lines = data.strip().split('\\n')\n",
    "    \n",
    "    # Extract the description part (after date)\n",
    "    description = '\\n'.join(lines[4:])\n",
    "    description = removingExtraLine(description)\n",
    "    return description\n",
    "\n",
    "\n",
    "\n",
    "# Extract description from the provided data\n",
    "description1 = extract_description(data1)\n",
    "description2 = extract_description(data2)\n",
    "\n",
    "# Print the descriptions\n",
    "print(\"Data 1 Description:\")\n",
    "print(description1)\n",
    "\n",
    "\n",
    "print(\"\\nData 2 Description:\")\n",
    "print(description2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8aadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Company</th>\n",
       "      <th>Position</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Field_of_Study</th>\n",
       "      <th>Graduation_Date</th>\n",
       "      <th>Certifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>New York</td>\n",
       "      <td>Skill1, Skill2, Skill3</td>\n",
       "      <td>Company1</td>\n",
       "      <td>Position1</td>\n",
       "      <td>Date1</td>\n",
       "      <td>Date2</td>\n",
       "      <td>Institution1</td>\n",
       "      <td>Degree1</td>\n",
       "      <td>Field1</td>\n",
       "      <td>Date5</td>\n",
       "      <td>Cert1, Cert2, Cert3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Company2</td>\n",
       "      <td>Position2</td>\n",
       "      <td>Date3</td>\n",
       "      <td>Date4</td>\n",
       "      <td>Institution2</td>\n",
       "      <td>Degree2</td>\n",
       "      <td>Field2</td>\n",
       "      <td>Date6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Location                  Skills   Company   Position Start_Date  \\\n",
       "0  John Doe  New York  Skill1, Skill2, Skill3  Company1  Position1      Date1   \n",
       "1      None      None                    None  Company2  Position2      Date3   \n",
       "\n",
       "  End_Date   Institution   Degree Field_of_Study Graduation_Date  \\\n",
       "0    Date2  Institution1  Degree1         Field1           Date5   \n",
       "1    Date4  Institution2  Degree2         Field2           Date6   \n",
       "\n",
       "        Certifications  \n",
       "0  Cert1, Cert2, Cert3  \n",
       "1                 None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given JSON data\n",
    "data = [\n",
    "    {\n",
    "        \"Name\": \"John Doe\",\n",
    "        \"Location\": \"New York\",\n",
    "        \"Skills\": [\"Skill1\", \"Skill2\", \"Skill3\"],\n",
    "        \"Jobs\": [\n",
    "            {\n",
    "                \"Company\": \"Company1\",\n",
    "                \"Position\": \"Position1\",\n",
    "                \"Start_Date\": \"Date1\",\n",
    "                \"End_Date\": \"Date2\"\n",
    "            },\n",
    "            {\n",
    "                \"Company\": \"Company2\",\n",
    "                \"Position\": \"Position2\",\n",
    "                \"Start_Date\": \"Date3\",\n",
    "                \"End_Date\": \"Date4\"\n",
    "            }\n",
    "        ],\n",
    "        \"Education\": [\n",
    "            {\n",
    "                \"Institution\": \"Institution1\",\n",
    "                \"Degree\": \"Degree1\",\n",
    "                \"Field_of_Study\": \"Field1\",\n",
    "                \"Graduation_Date\": \"Date5\"\n",
    "            },\n",
    "            {\n",
    "                \"Institution\": \"Institution2\",\n",
    "                \"Degree\": \"Degree2\",\n",
    "                \"Field_of_Study\": \"Field2\",\n",
    "                \"Graduation_Date\": \"Date6\"\n",
    "            }\n",
    "        ],\n",
    "        \"Certifications\": [\"Cert1\", \"Cert2\", \"Cert3\"]\n",
    "    },\n",
    "#     {\n",
    "#         \"Name\": \"Jane Smith\",\n",
    "#         # Profile data for Jane...\n",
    "#     }\n",
    "]\n",
    "\n",
    "# Create empty lists to store flattened data\n",
    "names = []\n",
    "locations = []\n",
    "skills = []\n",
    "companies = []\n",
    "positions = []\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "institutions = []\n",
    "degrees = []\n",
    "fields_of_study = []\n",
    "graduation_dates = []\n",
    "certifications = []\n",
    "\n",
    "# Loop through the JSON data and flatten it\n",
    "for profile in data:\n",
    "    names.append(profile[\"Name\"])\n",
    "    locations.append(profile.get(\"Location\", \"\"))\n",
    "    skills.append(\", \".join(profile.get(\"Skills\", [])))\n",
    "    \n",
    "    # Jobs\n",
    "    job_data = profile.get(\"Jobs\", [])\n",
    "    for job in job_data:\n",
    "        companies.append(job.get(\"Company\", \"\"))\n",
    "        positions.append(job.get(\"Position\", \"\"))\n",
    "        start_dates.append(job.get(\"Start_Date\", \"\"))\n",
    "        end_dates.append(job.get(\"End_Date\", \"\"))\n",
    "    \n",
    "    # Education\n",
    "    education_data = profile.get(\"Education\", [])\n",
    "    for education in education_data:\n",
    "        institutions.append(education.get(\"Institution\", \"\"))\n",
    "        degrees.append(education.get(\"Degree\", \"\"))\n",
    "        fields_of_study.append(education.get(\"Field_of_Study\", \"\"))\n",
    "        graduation_dates.append(education.get(\"Graduation_Date\", \"\"))\n",
    "    \n",
    "    certifications.append(\", \".join(profile.get(\"Certifications\", [])))\n",
    "\n",
    "# Determine the maximum length for each list\n",
    "max_len = max(len(names), len(locations), len(skills), len(companies), len(positions),\n",
    "              len(start_dates), len(end_dates), len(institutions), len(degrees),\n",
    "              len(fields_of_study), len(graduation_dates), len(certifications))\n",
    "\n",
    "# Fill shorter lists with placeholders (e.g., None) to match the maximum length\n",
    "def fill_list(lst, max_len):\n",
    "    while len(lst) < max_len:\n",
    "        lst.append(None)\n",
    "\n",
    "# Fill the lists to match the maximum length\n",
    "fill_list(names, max_len)\n",
    "fill_list(locations, max_len)\n",
    "fill_list(skills, max_len)\n",
    "fill_list(companies, max_len)\n",
    "fill_list(positions, max_len)\n",
    "fill_list(start_dates, max_len)\n",
    "fill_list(end_dates, max_len)\n",
    "fill_list(institutions, max_len)\n",
    "fill_list(degrees, max_len)\n",
    "fill_list(fields_of_study, max_len)\n",
    "fill_list(graduation_dates, max_len)\n",
    "fill_list(certifications, max_len)\n",
    "\n",
    "# Create a Pandas DataFrame from the flattened data\n",
    "df = pd.DataFrame({\n",
    "    \"Name\": names,\n",
    "    \"Location\": locations,\n",
    "    \"Skills\": skills,\n",
    "    \"Company\": companies,\n",
    "    \"Position\": positions,\n",
    "    \"Start_Date\": start_dates,\n",
    "    \"End_Date\": end_dates,\n",
    "    \"Institution\": institutions,\n",
    "    \"Degree\": degrees,\n",
    "    \"Field_of_Study\": fields_of_study,\n",
    "    \"Graduation_Date\": graduation_dates,\n",
    "    \"Certifications\": certifications\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8c7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
