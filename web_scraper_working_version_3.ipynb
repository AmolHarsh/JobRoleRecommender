{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28076a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all the  necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException  # This line is important\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "opts = Options ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157cc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89c139e0",
   "metadata": {},
   "source": [
    "# This section is for certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49385380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function used for waiting\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def skill_parser(text):\n",
    "    text = text.replace('·',',')\n",
    "    text = text[7:].strip().split(\",\")\n",
    "    for i in range(len(text)):\n",
    "        text[i] = text[i].strip()\n",
    "    result = ':'.join(text)\n",
    "    if result == None:\n",
    "        return \"nan\"\n",
    "    return result\n",
    "\n",
    "\n",
    "def certificationSection(url):\n",
    "    try:\n",
    "        url = os.path.join(url, \"details/certifications/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(45.7, 50.3))\n",
    "\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        certficate_name = \"\"\n",
    "        certificate_issue_authority = \"\"\n",
    "        certificate_issue_date = \"\"\n",
    "        certificate_skill = \"\"\n",
    "        for certification in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            certification_details = certification.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            certification_details_list = certification_details.find_elements(By.XPATH,\"*\")\n",
    "            certification_institution_elem = certification_details_list[1] if len(certification_details_list) > 1 else None\n",
    "            lines = certification_institution_elem.text.split('\\n')\n",
    "            temp = []\n",
    "            prev = \"\"\n",
    "            for line in lines:\n",
    "                if prev == line:\n",
    "                    pass\n",
    "                else:\n",
    "                    temp.append(line)\n",
    "                prev = line\n",
    "            certficate_name = certficate_name + \"-:-\" + temp[0]\n",
    "            certificate_issue_authority = certificate_issue_authority + \"-:-\" + temp[1] \n",
    "            certificate_issue_date = certificate_issue_date + \"-:-\" + temp[2]\n",
    "        #             certficate_name.append(temp[0])\n",
    "        #             certificate_issue_authority.append(temp[1])\n",
    "        #             certificate_issue_date.append(temp[2])\n",
    "            if len(temp)>3 and \"credential\" not in temp[3].lower():\n",
    "                skill = temp[3]\n",
    "\n",
    "                certificate_skill = certificate_skill + \"-:-\" + skill_parser(skill)\n",
    "        #                 certificate_skill.append(skill_parser(skill))\n",
    "            else:\n",
    "                certificate_skill = certificate_skill + \"-:-\" + \"nan\"\n",
    "                #certificate_skill.append(\"nan\")\n",
    "        return [certficate_name,certificate_issue_authority,certificate_issue_date,certificate_skill]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [\"nan\",\"nan\",\"nan\", \"nan\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf3de1",
   "metadata": {},
   "source": [
    "# This is solely for experience section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "def removingExtraLine(descrip):\n",
    "    \n",
    "    # Define a regular expression pattern to match a date range format\n",
    "    date_pattern = r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} · \\d+ mos\\b\"\n",
    "\n",
    "    # Use re.search() to find the date range pattern in the first line\n",
    "    match = re.search(date_pattern, descrip)\n",
    "\n",
    "    # If a match is found in the first line, remove that line\n",
    "    if match and match.start() == 0:\n",
    "        lines = descrip.split('\\n', 1)  # Split the data into lines, starting from the first newline\n",
    "        if len(lines) > 1:\n",
    "            descrip = lines[1]  # Keep the data after the first line\n",
    "            \n",
    "    return descrip\n",
    "\n",
    "\n",
    "# Function to extract description\n",
    "def extract_description(data):\n",
    "    # Split the data by lines\n",
    "    lines = data.strip().split('\\n')\n",
    "    \n",
    "    # Extract the description part (after date)\n",
    "    description = '\\n'.join(lines[4:])\n",
    "    description = removingExtraLine(description)\n",
    "    return description\n",
    "\n",
    "\n",
    "url = \"https://www.linkedin.com/in/apratim-chandra-singh-39a67a64/\"\n",
    "\n",
    "#The below function returns:\n",
    "#[experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "#\n",
    "def experienceSection(url):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        url = os.path.join(url, \"details/experience/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(55.7, 60.3))\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "\n",
    "        experience_section_position_title = \"\"\n",
    "        experience_section_from_date = \"\"\n",
    "        experience_section_to_date = \"\"\n",
    "        experience_section_duration = \"\"\n",
    "        experience_section_description = \"\"\n",
    "        experience_section_company = \"\"\n",
    "        experience_section_location = \"\"\n",
    "\n",
    "        for position in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            position = position.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            company_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "\n",
    "            # company elem\n",
    "            company_linkedin_url = company_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "            # position details\n",
    "            position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "            position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "            position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "            outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "\n",
    "            if len(outer_positions) == 4:\n",
    "                position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                location = outer_positions[3].find_element(By.TAG_NAME,\"span\").text\n",
    "            elif len(outer_positions) == 3:\n",
    "                if \"·\" in outer_positions[2].text:\n",
    "                    position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = \"\"\n",
    "                else:\n",
    "                    position_title = \"\"\n",
    "                    company = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "            \n",
    "            try:\n",
    "                print(\"work_times: \", work_times)\n",
    "            except:\n",
    "                work_times = \"nan\"\n",
    "                print(\"can't print work_T\")\n",
    "            times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "            duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "\n",
    "            from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "            to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "            if position_summary_text and len(position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")) > 1:\n",
    "                descriptions = position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")\n",
    "                for description in descriptions:\n",
    "                    res = description.find_element(By.TAG_NAME,\"a\").find_elements(By.XPATH,\"*\")\n",
    "                    position_title_elem = res[0] if len(res) > 0 else None\n",
    "                    work_times_elem = res[1] if len(res) > 1 else None\n",
    "                    location_elem = res[2] if len(res) > 2 else None\n",
    "\n",
    "\n",
    "                    location = location_elem.find_element(By.XPATH,\"*\").text if location_elem else None\n",
    "                    position_title = position_title_elem.find_element(By.XPATH,\"*\").find_element(By.TAG_NAME,\"*\").text if position_title_elem else \"\"\n",
    "                    work_times = work_times_elem.find_element(By.XPATH,\"*\").text if work_times_elem else \"\"\n",
    "                    times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "                    duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "                    from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "                    to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "\n",
    "                    if description:\n",
    "                        text = description.text\n",
    "                        description = extract_description(text)\n",
    "\n",
    "                    experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                    experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                    experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                    experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                    experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                    experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                    experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "                    \n",
    "            else:\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "\n",
    "                experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return [experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [\"nan\",\"nan\", \"nan\", \"nan\", \"nan\",  \"nan\", \"nan\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa635b90",
   "metadata": {},
   "source": [
    "# This is solely for educational feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12070a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "url = \"https://www.linkedin.com/in/apratim-chandra-singh-39a67a64/\"\n",
    "\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "#the function returns\n",
    "#[education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "def educationInfo(url):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        url = os.path.join(url,\"details/education/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(50.7, 55.3))\n",
    "        \n",
    "        main = wait_for_element_to_load(by = By.TAG_NAME, name = \"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        education_from_date = \"\"\n",
    "        education_to_date = \"\"\n",
    "        education_description = \"\"\n",
    "        education_degree = \"\"\n",
    "        education_institution_name = \"\"\n",
    "\n",
    "\n",
    "        for position in main_list.find_elements(By.CLASS_NAME,\"pvs-entity\"):\n",
    "                institution_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "                # company elem\n",
    "                institution_linkedin_url = institution_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "                # position details\n",
    "                position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "                position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "                position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "                outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "                institution_name = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                degree = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "                if len(outer_positions) > 2:\n",
    "                    times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    dates = times.split('-')\n",
    "                    from_date = dates[0].strip()\n",
    "                    to_date = dates[1].strip()\n",
    "                else:\n",
    "                    from_date = None\n",
    "                    to_date = None\n",
    "\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "                print()\n",
    "                education_from_date = education_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                education_to_date = education_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                education_description = education_description + \"-:-\" + emptyChecker(description)\n",
    "                education_degree = education_degree + \"-:-\" + emptyChecker(degree)\n",
    "                education_institution_name = education_institution_name + \"-:-\" + emptyChecker(institution_name)\n",
    "                \n",
    "#                 education_from_date.append(emptyChecker(from_date))\n",
    "#                 education_to_date.append(emptyChecker(to_date))\n",
    "#                 education_description.append(emptyChecker(description))\n",
    "#                 education_degree.append(emptyChecker(degree))\n",
    "#                 education_institution_name.append(emptyChecker(institution_name))\n",
    "\n",
    "#                 print(\"From Date:\", from_date)\n",
    "#                 print(\"To Date:\", to_date)\n",
    "#                 print(\"Description:\", description)\n",
    "#                 print(\"Degree:\", degree)\n",
    "#                 print(\"Institution Name:\", institution_name)\n",
    "#                 print(\"********************\")\n",
    "\n",
    "        return [education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        return [\"nan\", \"nan\", \"nan\", \"nan\", \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96421ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "663228ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef91b0b",
   "metadata": {},
   "source": [
    "# Main Code For Signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2038f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (116.0.5845.96) detected in PATH at /usr/local/bin/chromedriver might not be compatible with the detected chrome version (117.0.5938.92); currently, chromedriver 117.0.5938.92 is recommended for chrome 117.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to ensure all key data fields have a value\n",
    "\n",
    "def validate_field(field):\n",
    "    #if field is present pass if field:\n",
    "    if field:\n",
    "        pass\n",
    "    #if field is not present print text else:\n",
    "    else:\n",
    "        field = 'No results'\n",
    "    return field\n",
    "\n",
    "#driver get method() will navigate to a page given by the URL address.\n",
    "driver.get(\"https://www.linkedin.com/\")\n",
    "\n",
    "#locate email form by_class_name\n",
    "username = driver.find_element(By.ID, 'session_key')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "username.send_keys('2023mlpr@gmail.com')\n",
    "\n",
    "#sleep for 0.5 seconds\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate password form by_class_name\n",
    "password = driver.find_element(By.ID, 'session_password')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "password.send_keys('MLPR2023')\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate submit button by_xpath\n",
    "sign_in_button = driver.find_element(By.XPATH,'//*[@type=\"submit\"]')\n",
    "\n",
    "#.click() to mimic button click\n",
    "sign_in_button.click()\n",
    "\n",
    "sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095acd8",
   "metadata": {},
   "source": [
    "# Generating links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979a314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Machine+Learning+Engineer%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start=50\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/midhun-v-610b99108\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Machine+Learning+Engineer%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start=60\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/souvik-majumder-51b7881ba\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Machine+Learning+Engineer%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start=70\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/abhishek-iitk\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Machine+Learning+Engineer%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start=80\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/nutan-tripathy\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Machine+Learning+Engineer%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start=90\n",
      "checkpoint1\n",
      "working: https://in.linkedin.com/in/yerriswamy-vadde-29b256170\n",
      "checkpoint3\n",
      "checkpoint4\n",
      "Starting scraping:  [['https://in.linkedin.com/in/midhun-v-610b99108', 'https://in.linkedin.com/in/srpillai88', 'https://in.linkedin.com/in/gayatri-uparate-923122106', 'https://www.linkedin.com/in/manoranjan-kumar-00b54155', 'https://in.linkedin.com/in/shubhamagarwal12', 'https://in.linkedin.com/in/lokendra-carpenter?trk=public_profile_browsemap', 'https://in.linkedin.com/in/anirudh-sridhar-1905', 'https://in.linkedin.com/in/santhisenan', 'https://in.linkedin.com/in/ashutosh-verma-08073b184', 'https://in.linkedin.com/in/taruntandon88'], ['https://in.linkedin.com/in/souvik-majumder-51b7881ba', 'https://in.linkedin.com/in/gaurav-kumar-60b31a178', 'https://in.linkedin.com/in/deeapak-car-a-c-98770718a', 'https://in.linkedin.com/in/mohitsaini92', 'https://in.linkedin.com/in/dhruv-santoshwar-288455140', 'https://in.linkedin.com/in/sriram-puttagunta-27352a39', 'https://in.linkedin.com/in/prateek-kesharwani-pk27', 'https://in.linkedin.com/in/pulkit-tyagi-a33458141', 'https://in.linkedin.com/in/karishma-joshi-533957119', 'https://in.linkedin.com/in/suraj-arulmozhi-885822156'], ['https://in.linkedin.com/in/abhishek-iitk', 'https://in.linkedin.com/in/sayon-banerjee-4138a7179', 'https://in.linkedin.com/in/arun-kumar-tiwary-27a85698', 'https://in.linkedin.com/in/prashantgarg2', 'https://in.linkedin.com/in/mrhimanshu', 'https://in.linkedin.com/in/sagargoyal21', 'https://in.linkedin.com/in/garima-prashal-88815aba', 'https://in.linkedin.com/in/amitsrivastava91', 'https://in.linkedin.com/in/jyoti-kushwaha-505394172', 'https://in.linkedin.com/in/ranjeet-kumar-70513752'], ['https://in.linkedin.com/in/nutan-tripathy', 'https://in.linkedin.com/in/pankaj-kulria', 'https://in.linkedin.com/in/dixitbprajapati', 'https://in.linkedin.com/in/akshayklr057', 'https://in.linkedin.com/in/chirag-chauhan-9a220a195', 'https://in.linkedin.com/in/sagarnildas', 'https://in.linkedin.com/in/kaushiki-281788209', 'https://in.linkedin.com/in/ak-mur-22a520191', 'https://in.linkedin.com/in/sunny-kumar-59386022', 'https://in.linkedin.com/in/saurabh-verma-998411179'], ['https://in.linkedin.com/in/yerriswamy-vadde-29b256170', 'https://in.linkedin.com/in/rajeev-pratap-singh-9171214a', 'https://in.linkedin.com/in/akshay-r-87694a18b', 'https://in.linkedin.com/in/om-prakash-90b858189?trk=public_profile_browsemap_profile-result-card_result-card_full-click', 'https://in.linkedin.com/in/priti-pallavi-2908103b', 'https://in.linkedin.com/in/moeezdharwadkar', 'https://in.linkedin.com/in/ranjith-kumar95', 'https://in.linkedin.com/in/thirumoorthi-s-a0771324', 'https://in.linkedin.com/in/himanshu-aditya-2aa1a7112', 'https://in.linkedin.com/in/monish-ostwal-6a596715a']]\n"
     ]
    }
   ],
   "source": [
    "#sleep(15)\n",
    "\n",
    "csai = [\"Machine Learning Engineer\", \"AI Research Scientist\", \"Data Scientist\", \"Cybersecurity Analyst\", \"Software Developer\",\n",
    "    \"Natural Language Processing Engineer\", \"Blockchain Developer\", \"Cloud Computing Engineer\", \"AR/VR Developer\", \"Game Developer\",\n",
    "    \"DevOps Engineer\", \"IoT Developer\", \"Database Administrator\", \"Network Architect\", \"Quantitative Analyst\",\n",
    "    \"Systems Analyst\", \"Front-End Developer\", \"Back-End Developer\", \"Full Stack Developer\", \"UI/UX Designer\",\n",
    "    \"Ethical Hacker\", \"Mobile App Developer\", \"E-commerce Analyst\", \"Search Engine Specialist\", \"Information Security Manager\",\n",
    "    \"Business Intelligence Analyst\", \"QA Tester\", \"Tech Support Engineer\", \"Application Architect\", \"Infrastructure Architect\"]\n",
    "\n",
    "\n",
    "def role_tokeniser(job_role):\n",
    "    job_role  = job_role.replace(\" \",\"+\")\n",
    "    return job_role\n",
    "\n",
    "\n",
    "# for role in csai:\n",
    "# sleep(5)\n",
    "Jobdata = []\n",
    "lnks = []\n",
    "role = csai[0]\n",
    "for x in range(0,100,10):\n",
    "    \n",
    "\n",
    "    job_role = role_tokeniser(role)\n",
    "    link = f'https://www.google.com/search?q=site:linkedin.com/in/+AND+%22{job_role}%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start={x}'\n",
    "    print(link)\n",
    "    driver.get(link)\n",
    "    time.sleep(random.uniform(2.5,4.9))\n",
    "    print(\"checkpoint1\")\n",
    "    try:\n",
    "        linkedin_url = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[@jsname='UWckNb']\"))).get_attribute(\"href\")\n",
    "        print(\"working:\", linkedin_url)\n",
    "        linkedin_urls = [my_elem.get_attribute(\"href\") for my_elem in WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@jsname='UWckNb']\")))]\n",
    "        print(\"checkpoint3\")\n",
    "        lnks.append(linkedin_urls)\n",
    "        print(\"checkpoint4\")\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException: Elements not found within the specified time.\")\n",
    "\n",
    "print(\"Starting scraping: \", lnks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203064e",
   "metadata": {},
   "source": [
    "# Start Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1902ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26198544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# THIS IS THE CODE USED FOR ONLY ONE JOB PROFILE\n",
    "\n",
    "\n",
    "profile_data = []\n",
    "flag = True\n",
    "for x in lnks:\n",
    "    newProfile = {}\n",
    "    for i in x:\n",
    "        i = i + \"/\"\n",
    "#         \n",
    "        print(\"i\", i)\n",
    "        # Get the profile URL\n",
    "        driver.get(i)\n",
    "        time.sleep(random.uniform(2.5, 4.9))\n",
    "        newProfile = {}\n",
    "\n",
    "        # Assigning the source code for the web page to a variable\n",
    "        page_source = driver.page_source\n",
    "        sel = Selector(text=page_source)\n",
    "\n",
    "        # Extract name\n",
    "        name_element = driver.find_element(By.XPATH, '//h1[contains(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]')\n",
    "        name = name_element.text.strip() if name_element else None\n",
    "        print(name)\n",
    "        \n",
    "        # Extract job title\n",
    "        try:\n",
    "            job_title_element = driver.find_element(By.XPATH, '//div[contains(@class, \"text-body-medium break-words\")]')\n",
    "        except:\n",
    "            job_title_element = \"nan\"\n",
    "        job_title = job_title_element.text.strip() if job_title_element else None\n",
    "        print(job_title)\n",
    "        \n",
    "        #Extract about section\n",
    "        try:\n",
    "            about = driver.find_element(By.XPATH,'//div[contains(@class, \"pv-shared-text-with-see-more full-width t-14 t-normal t-black display-flex align-items-center\")]').text\n",
    "        except:\n",
    "            about = \"nan\"\n",
    "            \n",
    "        #Extracting the education\n",
    "        education = educationInfo(i)\n",
    "        print(education)\n",
    "        \n",
    "        \n",
    "        #Extracting the experience\n",
    "        experience = experienceSection(i)\n",
    "        print(experience)\n",
    "        \n",
    "        \n",
    "        #Extracting the certificate\n",
    "        certification = certificationSection(i)\n",
    "        print(certification)\n",
    "        \n",
    "        #linkedin link\n",
    "        link = i\n",
    "        newProfile[\"name\"] = [name]\n",
    "        newProfile[\"currentJobTitle\"] = job_title\n",
    "        newProfile[\"about\"] = about\n",
    "        newProfile[\"education_from_date\"] = education[0]\n",
    "        newProfile[\"education_to_date\"] = education[1]\n",
    "        newProfile[\"education_description\"] = education[2]\n",
    "        newProfile[\"education_degree\"] = education[3]\n",
    "        newProfile[\"education_institution_name\"] = education[4]\n",
    "        newProfile[\"experience_section_position_title\"] = experience[0]\n",
    "        newProfile[\"experience_section_from_date\"] = experience[1]\n",
    "        newProfile[\"experience_section_to_date\"] = experience[2]\n",
    "        newProfile[\"experience_section_description\"] = experience[3]\n",
    "        newProfile[\"experience_section_duration\"] = experience[4]\n",
    "        newProfile[\"experience_section_company\"] = experience[5]\n",
    "        newProfile[\"experience_section_location\"] = experience[6]\n",
    "        newProfile[\"certficate_name\"] = certification[0]\n",
    "        newProfile[\"certificate_issue_authority\"] = certification[1]\n",
    "        newProfile[\"certificate_issue_date\"] = certification[2]\n",
    "        newProfile[\"certificate_skill\"] = certification[3]\n",
    "        newProfile[\"linkedin_link\"] = link\n",
    "        if flag:\n",
    "            df = pd.DataFrame(newProfile)\n",
    "            flag = False\n",
    "        df = df.append(newProfile, ignore_index=True)\n",
    "#         with pd.ExcelWriter(\"linkedin_profiles.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "#             df.to_excel(writer, index=False, sheet_name='Sheet1', header=False)  # Set header=False to not overwrite existing headers\n",
    "\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7205c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to your Excel file after generating the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2950a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter(\"linkedin_profiles.xlsx\", mode='w', engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, index=False, sheet_name='Sheet1', header=True)  # Set header=False to not overwrite existing headers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6576fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f03c7b89b455d2f2fd8585d7feb9ffcca792263b227246f21873bad37e7985d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
