{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b01d89",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d509ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException  # This line is important\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "opts = Options ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c139e0",
   "metadata": {},
   "source": [
    "# This section is for certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49385380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function used for waiting\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def skill_parser(text):\n",
    "    text = text.replace('·',',')\n",
    "    text = text[7:].strip().split(\",\")\n",
    "    for i in range(len(text)):\n",
    "        text[i] = text[i].strip()\n",
    "    result = ':'.join(text)\n",
    "    if result == None:\n",
    "        return \"nan\"\n",
    "    return result\n",
    "\n",
    "\n",
    "def certificationSection(url):\n",
    "    try:\n",
    "        url = os.path.join(url, \"details/certifications/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(45.7, 50.3))\n",
    "\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        certficate_name = \"\"\n",
    "        certificate_issue_authority = \"\"\n",
    "        certificate_issue_date = \"\"\n",
    "        certificate_skill = \"\"\n",
    "        for certification in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            certification_details = certification.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            certification_details_list = certification_details.find_elements(By.XPATH,\"*\")\n",
    "            certification_institution_elem = certification_details_list[1] if len(certification_details_list) > 1 else None\n",
    "            lines = certification_institution_elem.text.split('\\n')\n",
    "            temp = []\n",
    "            prev = \"\"\n",
    "            for line in lines:\n",
    "                if prev == line:\n",
    "                    pass\n",
    "                else:\n",
    "                    temp.append(line)\n",
    "                prev = line\n",
    "            certficate_name = certficate_name + \"-:-\" + temp[0]\n",
    "            certificate_issue_authority = certificate_issue_authority + \"-:-\" + temp[1] \n",
    "            certificate_issue_date = certificate_issue_date + \"-:-\" + temp[2]\n",
    "        #             certficate_name.append(temp[0])\n",
    "        #             certificate_issue_authority.append(temp[1])\n",
    "        #             certificate_issue_date.append(temp[2])\n",
    "            if len(temp)>3 and \"credential\" not in temp[3].lower():\n",
    "                skill = temp[3]\n",
    "\n",
    "                certificate_skill = certificate_skill + \"-:-\" + skill_parser(skill)\n",
    "        #                 certificate_skill.append(skill_parser(skill))\n",
    "            else:\n",
    "                certificate_skill = certificate_skill + \"-:-\" + \"nan\"\n",
    "                #certificate_skill.append(\"nan\")\n",
    "        return [certficate_name,certificate_issue_authority,certificate_issue_date,certificate_skill]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [\"nan\",\"nan\",\"nan\", \"nan\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf3de1",
   "metadata": {},
   "source": [
    "# This is solely for experience section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "def removingExtraLine(descrip):\n",
    "    \n",
    "    # Define a regular expression pattern to match a date range format\n",
    "    date_pattern = r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} · \\d+ mos\\b\"\n",
    "\n",
    "    # Use re.search() to find the date range pattern in the first line\n",
    "    match = re.search(date_pattern, descrip)\n",
    "\n",
    "    # If a match is found in the first line, remove that line\n",
    "    if match and match.start() == 0:\n",
    "        lines = descrip.split('\\n', 1)  # Split the data into lines, starting from the first newline\n",
    "        if len(lines) > 1:\n",
    "            descrip = lines[1]  # Keep the data after the first line\n",
    "            \n",
    "    return descrip\n",
    "\n",
    "\n",
    "# Function to extract description\n",
    "def extract_description(data):\n",
    "    # Split the data by lines\n",
    "    lines = data.strip().split('\\n')\n",
    "    \n",
    "    # Extract the description part (after date)\n",
    "    description = '\\n'.join(lines[4:])\n",
    "    description = removingExtraLine(description)\n",
    "    return description\n",
    "\n",
    "\n",
    "# url = \"https://www.linkedin.com/in/apratim-chandra-singh-39a67a64/\"\n",
    "\n",
    "#The below function returns:\n",
    "#[experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "#\n",
    "def experienceSection(url):\n",
    "    try: \n",
    "        url = os.path.join(url, \"details/experience/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(55.7, 60.3))\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "\n",
    "        experience_section_position_title = \"\"\n",
    "        experience_section_from_date = \"\"\n",
    "        experience_section_to_date = \"\"\n",
    "        experience_section_duration = \"\"\n",
    "        experience_section_description = \"\"\n",
    "        experience_section_company = \"\"\n",
    "        experience_section_location = \"\"\n",
    "\n",
    "        for position in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            position = position.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            company_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "\n",
    "            # company elem\n",
    "            company_linkedin_url = company_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "            # position details\n",
    "            position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "            position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "            position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "            outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "\n",
    "            if len(outer_positions) == 4:\n",
    "                position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                location = outer_positions[3].find_element(By.TAG_NAME,\"span\").text\n",
    "            elif len(outer_positions) == 3:\n",
    "                if \"·\" in outer_positions[2].text:\n",
    "                    position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = \"\"\n",
    "                else:\n",
    "                    position_title = \"\"\n",
    "                    company = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "            \n",
    "            try:\n",
    "                print(\"work_times: \", work_times)\n",
    "            except:\n",
    "                work_times = \"nan\"\n",
    "                print(\"can't print work_T\")\n",
    "            times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "            duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "\n",
    "            from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "            to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "            if position_summary_text and len(position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")) > 1:\n",
    "                descriptions = position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")\n",
    "                for description in descriptions:\n",
    "                    res = description.find_element(By.TAG_NAME,\"a\").find_elements(By.XPATH,\"*\")\n",
    "                    position_title_elem = res[0] if len(res) > 0 else None\n",
    "                    work_times_elem = res[1] if len(res) > 1 else None\n",
    "                    location_elem = res[2] if len(res) > 2 else None\n",
    "\n",
    "\n",
    "                    location = location_elem.find_element(By.XPATH,\"*\").text if location_elem else None\n",
    "                    position_title = position_title_elem.find_element(By.XPATH,\"*\").find_element(By.TAG_NAME,\"*\").text if position_title_elem else \"\"\n",
    "                    work_times = work_times_elem.find_element(By.XPATH,\"*\").text if work_times_elem else \"\"\n",
    "                    times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "                    duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "                    from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "                    to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "\n",
    "                    if description:\n",
    "                        text = description.text\n",
    "                        description = extract_description(text)\n",
    "\n",
    "                    experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                    experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                    experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                    experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                    experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                    experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                    experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "                    \n",
    "            else:\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "\n",
    "                experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "\n",
    "        return [experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [\"nan\",\"nan\", \"nan\", \"nan\", \"nan\",  \"nan\", \"nan\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa635b90",
   "metadata": {},
   "source": [
    "# This is solely for educational feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12070a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "# The function returns education_from_date,education_to_date,education_description,education_degree, \n",
    "# education_institution_name]\n",
    "def educationInfo(url):\n",
    "    try:\n",
    "        url = os.path.join(url,\"details/education/\")\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(50.7, 55.3))\n",
    "        \n",
    "        main = wait_for_element_to_load(by = By.TAG_NAME, name = \"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        education_from_date = \"\"\n",
    "        education_to_date = \"\"\n",
    "        education_description = \"\"\n",
    "        education_degree = \"\"\n",
    "        education_institution_name = \"\"\n",
    "        for position in main_list.find_elements(By.CLASS_NAME,\"pvs-entity\"):\n",
    "                institution_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "                # company elem\n",
    "                institution_linkedin_url = institution_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "                # position details\n",
    "                position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "                position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "                position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "                outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "                institution_name = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                degree = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "                if len(outer_positions) > 2:\n",
    "                    times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    dates = times.split('-')\n",
    "                    from_date = dates[0].strip()\n",
    "                    to_date = dates[1].strip()\n",
    "                else:\n",
    "                    from_date = None\n",
    "                    to_date = None\n",
    "\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "                print()\n",
    "                education_from_date = education_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                education_to_date = education_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                education_description = education_description + \"-:-\" + emptyChecker(description)\n",
    "                education_degree = education_degree + \"-:-\" + emptyChecker(degree)\n",
    "                education_institution_name = education_institution_name + \"-:-\" + emptyChecker(institution_name)\n",
    "                \n",
    "#                 education_from_date.append(emptyChecker(from_date))\n",
    "#                 education_to_date.append(emptyChecker(to_date))\n",
    "#                 education_description.append(emptyChecker(description))\n",
    "#                 education_degree.append(emptyChecker(degree))\n",
    "#                 education_institution_name.append(emptyChecker(institution_name))\n",
    "\n",
    "#                 print(\"From Date:\", from_date)\n",
    "#                 print(\"To Date:\", to_date)\n",
    "#                 print(\"Description:\", description)\n",
    "#                 print(\"Degree:\", degree)\n",
    "#                 print(\"Institution Name:\", institution_name)\n",
    "#                 print(\"********************\")\n",
    "\n",
    "        return [education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        return [\"nan\", \"nan\", \"nan\", \"nan\", \"nan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663228ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef91b0b",
   "metadata": {},
   "source": [
    "# Main Code For Signing into Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to ensure all key data fields have a value\n",
    "\n",
    "def validate_field(field):\n",
    "    #if field is present pass if field:\n",
    "    if field:\n",
    "        pass\n",
    "    #if field is not present print text else:\n",
    "    else:\n",
    "        field = 'No results'\n",
    "    return field\n",
    "\n",
    "#driver get method() will navigate to a page given by the URL address.\n",
    "driver.get(\"https://www.linkedin.com/\")\n",
    "\n",
    "#locate email form by_class_name\n",
    "username = driver.find_element(By.ID, 'session_key')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "username.send_keys('ENTER USERNAME')\n",
    "\n",
    "#sleep for 0.5 seconds\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate password form by_class_name\n",
    "password = driver.find_element(By.ID, 'session_password')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "password.send_keys('ENTER PASSWORD')\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate submit button by_xpath\n",
    "sign_in_button = driver.find_element(By.XPATH,'//*[@type=\"submit\"]')\n",
    "\n",
    "#.click() to mimic button click\n",
    "sign_in_button.click()\n",
    "\n",
    "sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sleep(15)\n",
    "\n",
    "csai = [\"Business Analyst\"]\n",
    "\n",
    "\n",
    "def role_tokeniser(job_role):\n",
    "    job_role  = job_role.replace(\" \",\"+\")\n",
    "    return job_role\n",
    "\n",
    "\n",
    "Jobdata = []\n",
    "lnks = []\n",
    "role = csai[0]\n",
    "for x in range(0,100,10):\n",
    "    \n",
    "\n",
    "    job_role = role_tokeniser(role)\n",
    "    link = f'https://www.google.com/search?q=site:linkedin.com/in/+AND+%22{job_role}%22+AND+%22India%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start={x}'\n",
    "    print(link)\n",
    "    driver.get(link)\n",
    "    time.sleep(random.uniform(2.5,4.9))\n",
    "    print(\"checkpoint1\")\n",
    "    try:\n",
    "        linkedin_url = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[@jsname='UWckNb']\"))).get_attribute(\"href\")\n",
    "        print(\"working:\", linkedin_url)\n",
    "        linkedin_urls = [my_elem.get_attribute(\"href\") for my_elem in WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@jsname='UWckNb']\")))]\n",
    "        print(\"checkpoint3\")\n",
    "        lnks.append(linkedin_urls)\n",
    "        print(\"checkpoint4\")\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException: Elements not found within the specified time.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203064e",
   "metadata": {},
   "source": [
    "# Start Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26198544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profile_data = []\n",
    "flag = True\n",
    "for x in lnks:\n",
    "    newProfile = {}\n",
    "    for i in x:\n",
    "        i = i + \"/\"\n",
    "        print(\"i\", i)\n",
    "        # Get the profile URL\n",
    "        driver.get(i)\n",
    "        time.sleep(random.uniform(2.5, 4.9))\n",
    "        newProfile = {}\n",
    "\n",
    "        # Assigning the source code for the web page to a variable\n",
    "        page_source = driver.page_source\n",
    "        sel = Selector(text=page_source)\n",
    "\n",
    "        # Extract name\n",
    "        name_element = driver.find_element(By.XPATH, '//h1[contains(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]')\n",
    "        name = name_element.text.strip() if name_element else None\n",
    "        print(name)\n",
    "        \n",
    "        # Extract job title\n",
    "        try:\n",
    "            job_title_element = driver.find_element(By.XPATH, '//div[contains(@class, \"text-body-medium break-words\")]')\n",
    "        except:\n",
    "            job_title_element = \"nan\"\n",
    "        job_title = job_title_element.text.strip() if job_title_element else None\n",
    "        print(job_title)\n",
    "        \n",
    "        #Extract about section\n",
    "        try:\n",
    "            about = driver.find_element(By.XPATH,'//div[contains(@class, \"pv-shared-text-with-see-more full-width t-14 t-normal t-black display-flex align-items-center\")]').text\n",
    "        except:\n",
    "            about = \"nan\"\n",
    "            \n",
    "        #Extracting the education\n",
    "        education = educationInfo(i)\n",
    "        print(education)\n",
    "        \n",
    "        \n",
    "#         #Extracting the experience\n",
    "        # experience = experienceSection(i)\n",
    "        # print(experience)\n",
    "        \n",
    "        \n",
    "#         #Extracting the certificate\n",
    "#         certification = certificationSection(i)\n",
    "#         print(certification)\n",
    "        \n",
    "        #linkedin link\n",
    "        link = i\n",
    "        newProfile[\"name\"] = [name]\n",
    "        newProfile[\"currentJobTitle\"] = job_title\n",
    "        newProfile[\"about\"] = about\n",
    "        newProfile[\"education_from_date\"] = education[0]\n",
    "        newProfile[\"education_to_date\"] = education[1]\n",
    "        newProfile[\"education_description\"] = education[2]\n",
    "        newProfile[\"education_degree\"] = education[3]\n",
    "        newProfile[\"education_institution_name\"] = education[4]\n",
    "        # newProfile[\"experience_section_position_title\"] = experience[0]\n",
    "        # newProfile[\"experience_section_from_date\"] = experience[1]\n",
    "        # newProfile[\"experience_section_to_date\"] = experience[2]\n",
    "        # newProfile[\"experience_section_description\"] = experience[3]\n",
    "        # newProfile[\"experience_section_duration\"] = experience[4]\n",
    "        # newProfile[\"experience_section_company\"] = experience[5]\n",
    "        # newProfile[\"experience_section_location\"] = experience[6]\n",
    "        # newProfile[\"certficate_name\"] = certification[0]\n",
    "        # newProfile[\"certificate_issue_authority\"] = certification[1]\n",
    "        # newProfile[\"certificate_issue_date\"] = certification[2]\n",
    "        # newProfile[\"certificate_skill\"] = certification[3]\n",
    "        newProfile[\"linkedin_link\"] = link\n",
    "        if flag:\n",
    "            df = pd.DataFrame(newProfile)\n",
    "            flag = False\n",
    "        df = df.append(newProfile, ignore_index=True)\n",
    "        with pd.ExcelWriter(\"linkedin_profiles.xlsx\", mode='a', engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='Sheet1', header=False)  # Set header=False to not overwrite existing headers\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
