{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "\n",
    "import pandas as pd \n",
    "from parsel import Selector\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException  # This line is important\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "opts = Options ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initiating the chrome driver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Function to ensure all key data fields have a value\n",
    "\n",
    "def validate_field(field):\n",
    "    #if field is present pass if field:\n",
    "    if field:\n",
    "        pass\n",
    "    #if field is not present print text else:\n",
    "    else:\n",
    "        field = 'No results'\n",
    "    return field\n",
    "\n",
    "#driver get method() will navigate to a page given by the URL address.\n",
    "driver.get(\"https://www.linkedin.com/\")\n",
    "\n",
    "#locate email form by_class_name\n",
    "username = driver.find_element(By.ID, 'session_key')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "username.send_keys('2023mlpr@gmail.com')\n",
    "\n",
    "#sleep for 0.5 seconds\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate password form by_class_name\n",
    "password = driver.find_element(By.ID, 'session_password')\n",
    "\n",
    "#send_keys() to simulate key strokes\n",
    "password.send_keys('MLPR2023')\n",
    "sleep(0.5)\n",
    "\n",
    "#Locate submit button by_xpath\n",
    "sign_in_button = driver.find_element(By.XPATH,'//*[@type=\"submit\"]')\n",
    "\n",
    "#.click() to mimic button click\n",
    "sign_in_button.click()\n",
    "\n",
    "sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting profiles based on the keyword taken --- Here the keyword taken is Python + Developer\n",
    "\n",
    "sleep(5)\n",
    "Jobdata = []\n",
    "lnks = []\n",
    "for x in range(0,20,10):\n",
    "    driver.get(f'https://www.google.com/search?q=site:linkedin.com/in/+AND+%22Python+Developer%22+AND+%22Delhi%22&rlz=1C1CHZO_enIN1023IN1023&ei=jPaIY-mEGM6cseMPyZaNmAo&start={x}')\n",
    "    time.sleep(random.uniform(2.5,4.9))\n",
    "    try:\n",
    "        linkedin_url = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[@jsname='UWckNb']\"))).get_attribute(\"href\")\n",
    "        linkedin_urls = [my_elem.get_attribute(\"href\") for my_elem in WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, \"//a[@jsname='UWckNb']\")))]\n",
    "        lnks.append(linkedin_urls)\n",
    "    except TimeoutException:\n",
    "        print(\"TimeoutException: Elements not found within the specified time.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block for all the functions\n",
    "\n",
    "# Checks whether the string is empty or not\n",
    "\n",
    "def emptyChecker(string):\n",
    "    if string:\n",
    "        return string\n",
    "    else:\n",
    "        return \"nan\"\n",
    "\n",
    "# Used for waiting an element to load\n",
    "\n",
    "def wait_for_element_to_load(by=By.CLASS_NAME, name=\"pv-top-card\", base=None):\n",
    "    base = base or driver\n",
    "    return WebDriverWait(base,5).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (\n",
    "                    by,\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Function to extract description\n",
    "\n",
    "def extract_description(data):\n",
    "    # Split the data by lines\n",
    "    lines = data.strip().split('\\n')\n",
    "    \n",
    "    # Extract the description part (after date)\n",
    "    description = '\\n'.join(lines[4:])\n",
    "    description = removingExtraLine(description)\n",
    "    return description\n",
    "\n",
    "def removingExtraLine(descrip):\n",
    "    \n",
    "    # Define a regular expression pattern to match a date range format\n",
    "    date_pattern = r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} · \\d+ mos\\b\"\n",
    "\n",
    "    # Use re.search() to find the date range pattern in the first line\n",
    "    match = re.search(date_pattern, descrip)\n",
    "\n",
    "    # If a match is found in the first line, remove that line\n",
    "    if match and match.start() == 0:\n",
    "        lines = descrip.split('\\n', 1)  # Split the data into lines, starting from the first newline\n",
    "        if len(lines) > 1:\n",
    "            descrip = lines[1]  # Keep the data after the first line\n",
    "            \n",
    "    return descrip\n",
    "\n",
    "# Extracts the entire education section of the user\n",
    "\n",
    "def educationInfo(url):\n",
    "    try:\n",
    "        url = os.path.join(url,\"details/education\")\n",
    "        driver.get(url)\n",
    "        main = wait_for_element_to_load(by = By.TAG_NAME, name = \"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "        education_from_date = \"\"\n",
    "        education_to_date = \"\"\n",
    "        education_description = \"\"\n",
    "        education_degree = \"\"\n",
    "        education_institution_name = \"\"\n",
    "        \n",
    "        for position in main_list.find_elements(By.CLASS_NAME,\"pvs-entity\"):\n",
    "                institution_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "                # company elem\n",
    "                institution_linkedin_url = institution_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "                # position details\n",
    "                position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "                position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "                position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "                outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "                institution_name = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                degree = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "                if len(outer_positions) > 2:\n",
    "                    times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    dates = times.split('-')\n",
    "                    from_date = dates[0].strip()\n",
    "                    to_date = dates[1].strip()\n",
    "                else:\n",
    "                    from_date = None\n",
    "                    to_date = None\n",
    "\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "                print()\n",
    "                education_from_date = education_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                education_to_date = education_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                education_description = education_description + \"-:-\" + emptyChecker(description)\n",
    "                education_degree = education_degree + \"-:-\" + emptyChecker(degree)\n",
    "                education_institution_name = education_institution_name + \"-:-\" + emptyChecker(institution_name)\n",
    "        return [education_from_date,education_to_date,education_description,education_degree, education_institution_name]\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        return [\"nan\", \"nan\", \"nan\", \"nan\", \"nan\"]\n",
    "    \n",
    "# Extracts the entire experience section of the user\n",
    "\n",
    "def experienceSection(url):\n",
    "\n",
    "    try:    \n",
    "        url = os.path.join(url, \"details/experience\")\n",
    "        driver.get(url)\n",
    "        main = wait_for_element_to_load(by=By.TAG_NAME, name=\"main\")\n",
    "        main_list = wait_for_element_to_load(name=\"pvs-list\", base=main)\n",
    "\n",
    "        experience_section_position_title = \"\"\n",
    "        experience_section_from_date = \"\"\n",
    "        experience_section_to_date = \"\"\n",
    "        experience_section_duration = \"\"\n",
    "        experience_section_description = \"\"\n",
    "        experience_section_company = \"\"\n",
    "        experience_section_location = \"\"\n",
    "\n",
    "        for position in main_list.find_elements(By.XPATH,\"li\"):\n",
    "            position = position.find_element(By.CLASS_NAME,\"pvs-entity\")\n",
    "            company_logo_elem, position_details = position.find_elements(By.XPATH,\"*\")\n",
    "\n",
    "            # company elem\n",
    "            company_linkedin_url = company_logo_elem.find_element(By.XPATH,\"*\").get_attribute(\"href\")\n",
    "\n",
    "            # position details\n",
    "            position_details_list = position_details.find_elements(By.XPATH,\"*\")\n",
    "            position_summary_details = position_details_list[0] if len(position_details_list) > 0 else None\n",
    "            position_summary_text = position_details_list[1] if len(position_details_list) > 1 else None\n",
    "            outer_positions = position_summary_details.find_element(By.XPATH,\"*\").find_elements(By.XPATH,\"*\")\n",
    "\n",
    "            if len(outer_positions) == 4:\n",
    "                position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                location = outer_positions[3].find_element(By.TAG_NAME,\"span\").text\n",
    "            elif len(outer_positions) == 3:\n",
    "                if \"·\" in outer_positions[2].text:\n",
    "                    position_title = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    company = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = \"\"\n",
    "                else:\n",
    "                    position_title = \"\"\n",
    "                    company = outer_positions[0].find_element(By.TAG_NAME,\"span\").text\n",
    "                    work_times = outer_positions[1].find_element(By.TAG_NAME,\"span\").text\n",
    "                    location = outer_positions[2].find_element(By.TAG_NAME,\"span\").text\n",
    "\n",
    "            times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "            duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "\n",
    "            from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "            to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "            if position_summary_text and len(position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")) > 1:\n",
    "                descriptions = position_summary_text.find_element(By.CLASS_NAME,\"pvs-list\").find_element(By.CLASS_NAME,\"pvs-list\").find_elements(By.XPATH,\"li\")\n",
    "                for description in descriptions:\n",
    "                    res = description.find_element(By.TAG_NAME,\"a\").find_elements(By.XPATH,\"*\")\n",
    "                    position_title_elem = res[0] if len(res) > 0 else None\n",
    "                    work_times_elem = res[1] if len(res) > 1 else None\n",
    "                    location_elem = res[2] if len(res) > 2 else None\n",
    "                    location = location_elem.find_element(By.XPATH,\"*\").text if location_elem else None\n",
    "                    position_title = position_title_elem.find_element(By.XPATH,\"*\").find_element(By.TAG_NAME,\"*\").text if position_title_elem else \"\"\n",
    "                    work_times = work_times_elem.find_element(By.XPATH,\"*\").text if work_times_elem else \"\"\n",
    "                    times = work_times.split(\"·\")[0].strip() if work_times else \"\"\n",
    "                    duration = work_times.split(\"·\")[1].strip() if len(work_times.split(\"·\")) > 1 else None\n",
    "                    from_date = \" \".join(times.split(\" \")[:2]) if times else \"\"\n",
    "                    to_date = \" \".join(times.split(\" \")[3:]) if times else \"\"\n",
    "\n",
    "                    if description:\n",
    "                        text = description.text\n",
    "                        description = extract_description(text)\n",
    "                    experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                    experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                    experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                    experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                    experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                    experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                    experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "            else:\n",
    "                description = position_summary_text.text if position_summary_text else \"\"\n",
    "                experience_section_position_title = experience_section_position_title + \"-:-\" + emptyChecker(position_title)\n",
    "                experience_section_from_date = experience_section_from_date + \"-:-\" + emptyChecker(from_date)\n",
    "                experience_section_to_date = experience_section_to_date + \"-:-\" + emptyChecker(to_date)\n",
    "                experience_section_duration = experience_section_duration + \"-:-\" + emptyChecker(duration)\n",
    "                experience_section_description = experience_section_description + \"-:-\" + emptyChecker(description)\n",
    "                experience_section_company = experience_section_company + \"-:-\" + emptyChecker(company)\n",
    "                experience_section_location = experience_section_location + \"-:-\" + emptyChecker(location)\n",
    "        return [experience_section_position_title, experience_section_from_date, experience_section_to_date,experience_section_description , experience_section_duration, experience_section_company, experience_section_location]\n",
    "    except:\n",
    "        return [\"nan\",\"nan\", \"nan\", \"nan\", \"nan\",  \"nan\", \"nan\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data = []\n",
    "for x in lnks:\n",
    "    newProfile = {}\n",
    "    for i in x:\n",
    "        # Get the profile URL\n",
    "        driver.get(i)\n",
    "        time.sleep(random.uniform(2.5, 4.9))\n",
    "\n",
    "        # Assigning the source code for the web page to a variable\n",
    "        page_source = driver.page_source\n",
    "        sel = Selector(text=page_source)\n",
    "        \n",
    "        # Extract name\n",
    "        name_element = driver.find_element(By.XPATH, '//h1[contains(@class, \"text-heading-xlarge inline t-24 v-align-middle break-words\")]')\n",
    "        name = name_element.text.strip() if name_element else \"nan\"\n",
    "\n",
    "        # Extract job title\n",
    "        job_title_element = driver.find_element(By.XPATH, '//div[contains(@class, \"text-body-medium break-words\")]')\n",
    "        job_title = job_title_element.text.strip() if job_title_element else \"nan\"\n",
    "\n",
    "        #Extract about section\n",
    "        about = driver.find_element(By.XPATH,'//div[contains(@class, \"inline-show-more-text         inline-show-more-text--is-collapsed         inline-show-more-text--is-collapsed-with-line-clamp                            full-width\")]').text\n",
    "        about = about.text.strip() if about else \"nan\"\n",
    "\n",
    "        #Extracting the education\n",
    "        education = educationInfo(i)\n",
    "\n",
    "        #Extracting the experience\n",
    "        experience = experienceSection(i)\n",
    "\n",
    "        newProfile[\"name\"] = name_element\n",
    "        newProfile[\"currentJobTitle\"] = job_title\n",
    "        newProfile[\"about\"] = about\n",
    "        newProfile[\"education_from_date\"] = education[0]\n",
    "        newProfile[\"education_to_date\"] = education[1]\n",
    "        newProfile[\"education_description\"] = education[2]\n",
    "        newProfile[\"education_degree\"] = education[3]\n",
    "        newProfile[\"education_institution_name\"] = education[4]\n",
    "\n",
    "        newProfile[\"experience_section_position_title\"] = experience[0]\n",
    "        newProfile[\"experience_section_from_date\"] = experience[1]\n",
    "        newProfile[\"experience_section_to_date\"] = experience[2]\n",
    "        newProfile[\"experience_section_description\"] = experience[3]\n",
    "        newProfile[\"experience_section_duration\"] = experience[4]\n",
    "        newProfile[\"experience_section_company\"] = experience[5]\n",
    "        newProfile[\"experience_section_location\"] = experience[6]\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
