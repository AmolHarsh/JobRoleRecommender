{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the necessary libraries\n",
    "from langchain.llms import OpenAIChat\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "import logging \n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor\n",
    "import sys\n",
    "import json\n",
    "from langchain.agents.tools import Tool\n",
    "import os\n",
    "os.environ[\"LOG_DIR\"]=\".\"\n",
    "os.environ[\"WORDLIST_DIR\"]=\".\"\n",
    "import tiktoken\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamankhandelwal/opt/anaconda3/envs/ml/lib/python3.10/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********COMPANY AND ORGANISATION SECTION********\n",
      "This is the company extraction for a particular person\n",
      "HEHEHEHEHEH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-pLKtRqCiXvWQksUJEtyBs2MZ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEHEHEHEHEH\n",
      "['PES University', 'Cognizant', 'LatentView Analytics', 'Unilever', 'BRIDGEi2i Analytics Solutions']\n"
     ]
    }
   ],
   "source": [
    "class TaskExecution():\n",
    "    def __init__(self):\n",
    "        self.prompt = \"\"\"\n",
    "        You are an expert in summarising and extracting keywords. You will be given a paragraph as input. Your task is to extract all the necessary and relevant keywords from the inputted \n",
    "        paragraph, which are similar or match the job role: {role}.\n",
    "\n",
    "        Return all the extracted keywords in the form of python list.\n",
    "        The inputted paragraph is:\n",
    "        {input}\"\"\"\n",
    "\n",
    "        self.company_prompt = \"\"\" \n",
    "        \n",
    "        You will be given a paragraph as an input, which is basically an experience section. Your task is to extract the names of the companies (if present), the person has explicitly stated that he has worked in.\n",
    "\n",
    "        Return the output in python list format.\n",
    "\n",
    "        The input paragraph is:\n",
    "        {input}\n",
    "        \"\"\"\n",
    "        self.llm = OpenAIChat(model_name='gpt-3.5-turbo',openai_api_key=\"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\",temperature=0)\n",
    "\n",
    "    def extract_keywords(self,about,role):\n",
    "        prompt = PromptTemplate(input_variables=['role','input'],template=self.prompt)\n",
    "        chain = LLMChain(llm=self.llm, prompt = prompt)\n",
    "        output = chain.run({'input':about,'role':role})\n",
    "        print(output)\n",
    "    \n",
    "    def extract_company(self,input):\n",
    "        company_prompt = PromptTemplate(input_variables=['input'],template=self.company_prompt)\n",
    "        chain = LLMChain(llm=self.llm, prompt = company_prompt)\n",
    "        output = chain.run({\"input\":input})\n",
    "        print(\"HEHEHEHEHEH\")\n",
    "        return(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    about = \"I am a Data Scientist at Networth Corp. Before joining the company I have completed a full-fledged Data Science course wherein I gained practical knowledge on how to collect, analyze and interpret data. I have a keen interest in analytics, machine learning, sentiment analysis, and data processing. I have a strong desire to learn and seek out new relevant technologies. As a Data Scientist, I also do have strong business acumen, a problem-solving attitude, and advanced knowledge of applied mathematics.\"\n",
    "    # experience = \"\"\"Anshu is a Full Stack Data Scientist with expertise in Text analytics, Data-Modelling and Deployment in distributed environment. Current he looks after Meesho's Fraud Detection Systems.\n",
    "    #             In his previous inning he was working for India's largest logistic firm Delivery as Senior data scientist where he was primarily involved in Location Intelligence and dealt with unstructured Addresses and Geocodes.\n",
    "    #             He believes in building fault-tollerance and scalable systems using tools like Apache Spark, Kubernetes, Docker and AWS Sagemaker. Python and GoLang is his favourite programming languages.\n",
    "    #             Reach out if you want to connect at: annshu0641@gmail.com\"\"\"\n",
    "    experience = \"\"\" \n",
    ">> Have 5+ years of experience in Fintech/NBFC's as Data Scientist. Over 3 years of experience in managing/mentoring Data Scientists, Analysts and Interns.\n",
    "\n",
    ">>Have 5+ years of Experience with advanced SQL \n",
    "\n",
    ">> Experience in extracting data from multiple sources using Python, SQL & KNIME.\n",
    "\n",
    ">> Good experience with data science libraries such as numpy, pandas, sqlalchemy, pymongo, datetime, etc.\n",
    "\n",
    ">> Exploratory data analysis using data science libraries like scorecardpy and pandas_profiling.\n",
    "\n",
    ">> Feature engineering with Python - Missing value, outlier handling, transforming variables and reshaping data using packages like pandas, numpy, sklearn & scorecardpy\n",
    "\n",
    ">> Deployed several Credit Risk Scorecard (ML) models using AWS and Microsoft Azure stack.\n",
    "\n",
    ">> Hands on experience with Tree based algorithms(Decision Trees, XGBoost, Random Forest)\n",
    "\n",
    ">> Good knowledge on advanced machine learning techniques such as k-NN, Naïve Bayes etc.\n",
    "\n",
    ">> Basic understanding of deep learning and natural language processing.\n",
    "\n",
    ">> Worked closely with marketing, product, technology, tele-calling, credit & collections teams.\n",
    "\n",
    ">> Excellent oral and written communication skills to communicate complex data science results to non-technical business and management teams.\n",
    "\n",
    ">> Carried out various ad-hoc analyses to solve business problems, automate and optimise repetitive processes.\n",
    "\n",
    ">> Designed, developed and deployed Tableau and PowerBI dashboards to track key business metrics.\n",
    "\n",
    ">> Collaborated with Database teams in designing the data structure which allowed to create analysis friendly tables avoiding complex ETL processes.\"\"\"\n",
    "\n",
    "    # experience = \"\"\" -:-Freelance-:-ISRO - Indian Space Research Organization · Full-time-:-Samsung Electronics · Full-time-:-Full-time · 1 yr 11 mos-:-Full-time · 1 yr 11 mos-:-Airbnb · Full-time-:-BYJU'S · Full-time-:-Tata Consultancy Services · Full-time-:-Swiggy · Full-time-:-CRED · Internship-:-airtel · Full-time\"\"\"\n",
    "    \n",
    "    job_role = \"Data Scientist\"\n",
    "    obj= TaskExecution()\n",
    "    # output = obj.extract_keywords(about,job_role)\n",
    "    # print(type(output))\n",
    "    # print(\"************ SUMMARISED EXPERIENCE SECTION *************\")\n",
    "    # experience_output = obj.extract_keywords(experience,job_role)\n",
    "    # print(type(experience_output))\n",
    "    print(\"**********COMPANY AND ORGANISATION SECTION********\")\n",
    "    \n",
    "\n",
    "    print(\"This is the company extraction for a particular person\")\n",
    "\n",
    "    # CASE 1: WHEN THE EXPERIENCE SECTION COMPANY HAS AND THE CURRENT JOB TITLE HAS  \n",
    "\n",
    "    # experience section company\n",
    "    a = \"-:-Unilever · Full-time-:-Unilever · Full-time-:-Unilever · Full-time-:-PES University · Freelance-:-PES University · Freelance-:-PES University · Freelance-:-BRIDGEi2i Analytics Solutions · Full-time-:-LatentView Analytics · Full-time-:-Cognizant · Full-time\"\n",
    "\n",
    "    #current job title\n",
    "    b = \"Manager Data Scientist at Unilever | Top 10 Data Scientist in India |Speaker | Mentor | Analytics Trainer | Coach | Published Author\"\n",
    "\n",
    "    experience_comapny_set = ast.literal_eval(obj.extract_company(a))\n",
    "    current_job_title = ast.literal_eval(obj.extract_company(b))\n",
    "\n",
    "    company = list(set(current_job_title) | set(experience_comapny_set))\n",
    "    print(company)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
